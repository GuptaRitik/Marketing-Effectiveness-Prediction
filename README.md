<p align="center"> 
</p>
<h1 align="center"> Bank Marketing Effectiveness Prediction </h1>
<h3 align="center"><a href="https://certificates.almabetter.com/en/verify/61517648916458"> AlmaBetter Verified Project </a> </h5>

This project aims to help a bank increase its term deposits by using data from direct marketing campaigns (phone calls) to predict customer response and target the most likely customers. This will enable the bank to optimize its marketing strategy, reduce costs and improve customer satisfaction. The project will use machine learning techniques to analyze customer features, such as demographics and transaction history, and identify patterns and trends that indicate customer saving behaviors. The project will also evaluate the effectiveness of different marketing channels and messages and provide recommendations for future campaigns. The project will deliver a predictive model, a customer segmentation and a marketing plan.

<h2> :floppy_disk: Project Files Description</h2>
<p>This Project contain 4 Files:</p>
<ul>
  <li><b>NoteBook</b> - Includes all the colab notebooks available for the project.</li>
  <li><b>Presentation</b> - Has Presentation of the whole project in file.</li>
  <li><b>Technical Document</b> - Included a word file for technical details of the whole project.</li>
  <li><b>Requirements</b> - All the required libraries for the project with their version.</li>
  <li><b>Data</b> - Dataset CSV file link from the google drive.</li>
</ul>


<h2> :book: Extreme Gradient Boost</h2>

<p>Extreme Gradient Boost (XGBoost) is a powerful and efficient framework for implementing gradient boosting algorithms. It builds an ensemble of weak learners, typically decision trees, that are sequentially fitted to the residuals of the previous learners. XGBoost uses a novel tree learning algorithm that handles sparsity, missing values, and regularization. It also supports parallel and distributed computing, as well as various objective functions and evaluation metrics.
</p>

